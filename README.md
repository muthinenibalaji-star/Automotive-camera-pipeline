# Automotive Camera Pipeline - Containerized Deployment

Real-time perception pipeline for automotive exterior light detection and state estimation.

## ðŸŽ¯ Overview

This containerized solution provides a complete, production-ready perception system for:
- **Real-time video processing** from multiple camera sources
- **Light detection** using RTMDet (MMDetection)
- **Multi-object tracking** with ByteTrack
- **State estimation** (ON/OFF/BLINKING) for automotive lights
- **HIL test bench integration** with ECU.TEST compatibility

## ðŸš€ Quick Start (Windows)

### Prerequisites

1. **Windows 10/11** (64-bit) with WSL2 enabled
2. **Docker Desktop** 4.0+ with WSL2 backend
3. **NVIDIA GPU** (RTX series recommended) with latest drivers
4. **16GB+ RAM** recommended
5. **50GB+ free disk space**

### One-Click Setup

1. **Download this repository** to your local machine

2. **Open PowerShell as Administrator**
   - Press `Win + X`
   - Select "Windows PowerShell (Admin)" or "Terminal (Admin)"

3. **Navigate to the project directory**
   ```powershell
   cd C:\path\to\automotive-camera-pipeline
   ```

4. **Run the setup script**
   ```powershell
   .\setup-windows.ps1
   ```

The script will:
- âœ… Verify Docker installation
- âœ… Check NVIDIA GPU drivers
- âœ… Create project structure
- âœ… Generate default configurations
- âœ… Build Docker container (~10-15 minutes)

## ðŸ“‹ Manual Setup (Alternative)

### Step 1: Install Docker Desktop

1. Download from: https://www.docker.com/products/docker-desktop
2. Install with WSL2 backend enabled
3. **Enable GPU support:**
   - Open Docker Desktop
   - Settings â†’ Resources â†’ WSL Integration
   - Enable integration for your WSL2 distro

### Step 2: Install NVIDIA Container Toolkit (WSL2)

Open WSL2 terminal and run:

```bash
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

### Step 3: Build Container

```powershell
docker-compose build
```

## ðŸŽ® Usage

### Basic Operation

**Start the pipeline:**
```powershell
docker-compose up
```

**Start in background (detached):**
```powershell
docker-compose up -d
```

**View logs:**
```powershell
docker-compose logs -f automotive-pipeline
```

**Stop the pipeline:**
```powershell
docker-compose down
```

### Development Mode

**Start Jupyter Notebook:**
```powershell
docker-compose --profile dev up jupyter-dev
```
Access at: http://localhost:8888

**Start TensorBoard (monitoring):**
```powershell
docker-compose --profile monitoring up tensorboard
```
Access at: http://localhost:6006

### Running Tests

```powershell
docker-compose run automotive-pipeline python -m pytest tests/
```

## ðŸ“ Project Structure

```
automotive-camera-pipeline/
â”œâ”€â”€ Dockerfile                  # Container definition
â”œâ”€â”€ docker-compose.yml          # Service orchestration
â”œâ”€â”€ setup-windows.ps1          # Windows setup script
â”œâ”€â”€ README.md                  # This file
â”‚
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ main.py               # Pipeline entry point
â”‚   â”œâ”€â”€ camera/               # Camera handling
â”‚   â”œâ”€â”€ detection/            # Object detection
â”‚   â”œâ”€â”€ tracking/             # Multi-object tracking
â”‚   â”œâ”€â”€ state_estimation/     # Light state logic
â”‚   â””â”€â”€ utils/                # Utilities
â”‚
â”œâ”€â”€ configs/                   # Configuration files
â”‚   â””â”€â”€ pipeline_config.yaml  # Main config
â”‚
â”œâ”€â”€ models/                    # Model checkpoints
â”‚   â””â”€â”€ rtmdet_weights.pth    # Place your weights here
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/                # Input videos/images
â”‚   â”œâ”€â”€ output/               # Perception results (JSON)
â”‚   â””â”€â”€ datasets/             # Training/validation data
â”‚
â”œâ”€â”€ logs/                      # Application logs
â”œâ”€â”€ tests/                     # Unit tests
â””â”€â”€ notebooks/                 # Jupyter notebooks
```

## âš™ï¸ Configuration

Edit `configs/pipeline_config.yaml`:

### Camera Configuration

```yaml
cameras:
  camera_0:
    source_type: "usb"        # Options: usb, dataset, industrial
    source: 0                 # Device index or video path
    width: 1920
    height: 1080
    fps: 30
```

**Supported sources:**
- `usb`: USB webcam (source: device index like `0`, `1`)
- `dataset`: Video file (source: `"path/to/video.mp4"`)
- `industrial`: OBBRec Femto Bolt (source: IP address)

### Detection Settings

```yaml
detection:
  model_type: "rtmdet"
  checkpoint_path: "models/rtmdet_weights.pth"
  confidence_threshold: 0.5
  fp16: true                  # Enable FP16 for faster inference
  
  classes:
    - "left_indicator"
    - "right_indicator"
    - "brake_light"
    - "reverse_light"
    - "headlight"
    - "fog_light"
```

### State Estimation

```yaml
state_estimation:
  on_threshold: 120            # Brightness threshold for ON state
  off_threshold: 50            # Brightness threshold for OFF state
  
  blink_frequency_hz: [1.0, 2.0]  # Expected blink frequency range
  blink_window_frames: 60         # Analysis window size
  temporal_window: 5              # Smoothing window
```

## ðŸŽ¯ Use Cases

### 1. Live Camera Testing

```powershell
# Edit configs/pipeline_config.yaml
cameras:
  camera_0:
    source_type: "usb"
    source: 0

# Run pipeline
docker-compose up
```

### 2. Dataset Processing

```powershell
# Place videos in data/input/
# Edit configs/pipeline_config.yaml
cameras:
  camera_0:
    source_type: "dataset"
    source: "/app/data/input/test_video.mp4"

# Run pipeline
docker-compose up
```

Results saved to `data/output/results.json`

### 3. Multi-Camera Setup

```yaml
system:
  num_cameras: 4

cameras:
  camera_0:
    source_type: "usb"
    source: 0
  camera_1:
    source_type: "usb"
    source: 1
  camera_2:
    source_type: "industrial"
    source: "192.168.1.100"
  camera_3:
    source_type: "dataset"
    source: "/app/data/input/rear_view.mp4"
```

## ðŸ“Š Output Format

Results are saved as timestamped JSON:

```json
{
  "timestamp": "2024-01-30T10:30:45.123456",
  "frame_id": 1234,
  "detections": [
    {
      "track_id": 5,
      "class": "left_indicator",
      "bbox": [100, 200, 50, 30],
      "confidence": 0.95,
      "state": "BLINKING",
      "intensity": 215,
      "blink_frequency": 1.5
    }
  ],
  "latency_ms": 45.2
}
```

## ðŸ”§ Troubleshooting

### Docker Build Fails

**Issue:** Build fails with network errors

**Solution:**
```powershell
# Configure Docker DNS
# Docker Desktop â†’ Settings â†’ Docker Engine
# Add to JSON config:
{
  "dns": ["8.8.8.8", "8.8.4.4"]
}
```

### GPU Not Detected

**Issue:** `CUDA not available` error

**Solution:**
1. Update NVIDIA drivers: https://www.nvidia.com/Download/index.aspx
2. Install NVIDIA Container Toolkit (see Manual Setup)
3. Restart Docker Desktop
4. Verify GPU access:
   ```powershell
   docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
   ```

### Camera Not Accessible

**Issue:** Cannot access USB camera

**Solution:**
1. Close all applications using the camera
2. Check camera index:
   ```powershell
   # In WSL2
   ls /dev/video*
   ```
3. Update `docker-compose.yml` device mappings

### Slow Inference

**Issue:** Processing slower than expected

**Solution:**
1. Enable FP16 in config: `fp16: true`
2. Reduce resolution in camera config
3. Verify GPU usage:
   ```powershell
   nvidia-smi -l 1
   ```

## ðŸŽ“ Team Onboarding

### For New Team Members

1. **Clone repository** to your Windows machine
2. **Run setup script** (one-time): `.\setup-windows.ps1`
3. **Place model weights** in `models/` directory
4. **Configure cameras** in `configs/pipeline_config.yaml`
5. **Start pipeline**: `docker-compose up`

### For Developers

1. **Mount source code** is auto-enabled in `docker-compose.yml`
2. **Edit code** in `src/` - changes reflect immediately
3. **Restart container** to reload: `docker-compose restart`
4. **Run tests**: `docker-compose run automotive-pipeline pytest`
5. **Debug with Jupyter**: `docker-compose --profile dev up jupyter-dev`

## ðŸ“ˆ Performance Benchmarks

| Configuration | Latency | FPS | GPU Usage |
|--------------|---------|-----|-----------|
| Single camera, RTX 3080, FP16 | 35ms | 28 | 45% |
| Dual camera, RTX 3080, FP16 | 52ms | 19 | 72% |
| Single camera, RTX A5000, FP16 | 28ms | 35 | 38% |
| Quad camera, RTX A5000, FP16 | 78ms | 12 | 88% |

## ðŸ” Security Notes

- Container runs in **privileged mode** for camera access
- Production deployment should restrict privileges
- Review `docker-compose.yml` security settings before deploying

## ðŸ†˜ Support

**Common Issues:**
- Check `logs/` directory for detailed error logs
- Review Docker logs: `docker-compose logs`
- Verify GPU: `nvidia-smi`

**For Help:**
- Create issue in repository
- Contact team lead
- Check documentation in `docs/`

## ðŸ“„ License

Internal use only - proprietary system for automotive validation.

## ðŸ”„ Updates

Pull latest changes:
```powershell
git pull
docker-compose build
docker-compose up -d
```

## ðŸŽ‰ Success Indicators

âœ… Docker container builds without errors
âœ… GPU detected: `nvidia-smi` works in container
âœ… Camera feed accessible
âœ… Detection confidence > 0.5
âœ… Tracking IDs stable across frames
âœ… State estimation accurate
âœ… JSON output generated in `data/output/`
âœ… End-to-end latency < 100ms

---

**Version:** 1.0.0  
**Last Updated:** January 2026  
**Maintained By:** Automotive Perception Team
